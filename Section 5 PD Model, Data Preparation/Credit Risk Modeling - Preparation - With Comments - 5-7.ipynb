{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "The dataset contains all available data for more than 800,000 consumer loans issued from 2007 to 2015 by Lending Club: a large US peer-to-peer lending company. There are several different versions of this dataset. We have used a version available on kaggle.com. You can find it here: https://www.kaggle.com/wendykan/lending-club-loan-data/version/1\n",
    "We divided the data into two periods because we assume that some data are available at the moment when we need to build Expected Loss models, and some data comes from applications after. Later, we investigate whether the applications we have after we built the Probability of Default (PD) model have similar characteristics with the applications we used to build the PD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_backup = pd.read_csv('loan_data_2007_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data_backup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "# Sets the pandas dataframe options to display all columns/ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.columns.values\n",
    "# Displays all column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.info()\n",
    "# Displays column names, complete (non-missing) cases per column, and datatype per column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing few continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['emp_length'].unique()\n",
    "# Displays unique values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['emp_length_int'] = loan_data['emp_length'].str.replace('\\+ years', '')\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace('< 1 year', str(0))\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace('n/a',  str(0))\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace(' years', '')\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace(' year', '')\n",
    "# We store the preprocessed ‘employment length’ variable in a new variable called ‘employment length int’,\n",
    "# We assign the new ‘employment length int’ to be equal to the ‘employment length’ variable with the string ‘+ years’\n",
    "# replaced with nothing. Next, we replace the whole string ‘less than 1 year’ with the string ‘0’.\n",
    "# Then, we replace the ‘n/a’ string with the string ‘0’. Then, we replace the string ‘space years’ with nothing.\n",
    "# Finally, we replace the string ‘space year’ with nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data['emp_length_int'][0])\n",
    "# Checks the datatype of a single element of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['emp_length_int'] = pd.to_numeric(loan_data['emp_length_int'])\n",
    "# Transforms the values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data['emp_length_int'][0])\n",
    "# Checks the datatype of a single element of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['earliest_cr_line']\n",
    "# Displays a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['earliest_cr_line_date'] = pd.to_datetime(loan_data['earliest_cr_line'], format = '%b-%y')\n",
    "# Extracts the date and the time from a string variable that is in a given format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(loan_data['earliest_cr_line_date'][0])\n",
    "# Checks the datatype of a single element of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2017-12-01') - loan_data['earliest_cr_line_date']\n",
    "# Calculates the difference between two dates and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we are now in December 2017\n",
    "loan_data['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - loan_data['earliest_cr_line_date']) / np.timedelta64(1, 'M')))\n",
    "# We calculate the difference between two dates in months, turn it to numeric datatype and round it.\n",
    "# We save the result in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['mths_since_earliest_cr_line'].describe()\n",
    "# Shows some descriptive statisics for the values of a column.\n",
    "# Dates from 1969 and before are not being converted well, i.e., they have become 2069 and similar,\n",
    "# and negative differences are being calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.loc[: , ['earliest_cr_line', 'earliest_cr_line_date', 'mths_since_earliest_cr_line']][loan_data['mths_since_earliest_cr_line'] < 0]\n",
    "# We take three columns from the dataframe. Then, we display them only for the rows where a variable has negative value.\n",
    "# There are 2303 strange negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['mths_since_earliest_cr_line'][loan_data['mths_since_earliest_cr_line'] < 0] = loan_data['mths_since_earliest_cr_line'].max()\n",
    "# We set the rows that had negative differences to the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(loan_data['mths_since_earliest_cr_line'])\n",
    "# Calculates and shows the minimum value of a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['term'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['term_int'] = loan_data['term'].str.replace(' months', '')\n",
    "# We replace a string with another string, in this case, with an empty strng (i.e. with nothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['term_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data['term_int'][25])\n",
    "# Checks the datatype of a single element of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['term_int'] = pd.to_numeric(loan_data['term'].str.replace(' months', ''))\n",
    "# We remplace a string from a variable with another string, in this case, with an empty strng (i.e. with nothing).\n",
    "# We turn the result to numeric datatype and save it in another variable.\n",
    "loan_data['term_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data['term_int'][0])\n",
    "# Checks the datatype of a single element of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['issue_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we are now in December 2017\n",
    "loan_data['issue_d_date'] = pd.to_datetime(loan_data['issue_d'], format = '%b-%y')\n",
    "# Extracts the date and the time from a string variable that is in a given format.\n",
    "loan_data['mths_since_issue_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - loan_data['issue_d_date']) / np.timedelta64(1, 'M')))\n",
    "# We calculate the difference between two dates in months, turn it to numeric datatype and round it.\n",
    "# We save the result in a new variable.\n",
    "loan_data['mths_since_issue_d'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing few discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.info()\n",
    "# Displays column names, complete (non-missing) cases per column, and datatype per column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to preprocess the following discrete variables: grade, sub_grade, home_ownership, verification_status, loan_status, purpose, addr_state, initial_list_status. Most likely, we are not going to use sub_grade, as it overlaps with grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(loan_data['grade'])\n",
    "# Create dummy variables from a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(loan_data['grade'], prefix = 'grade', prefix_sep = ':')\n",
    "# Create dummy variables from a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_dummies = [pd.get_dummies(loan_data['grade'], prefix = 'grade', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['sub_grade'], prefix = 'sub_grade', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['home_ownership'], prefix = 'home_ownership', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['verification_status'], prefix = 'verification_status', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['loan_status'], prefix = 'loan_status', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['purpose'], prefix = 'purpose', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['addr_state'], prefix = 'addr_state', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['initial_list_status'], prefix = 'initial_list_status', prefix_sep = ':')]\n",
    "# We create dummy variables from all 8 original independent variables, and save them into a list.\n",
    "# Note that we are using a particular naming convention for all variables: original variable name, colon, category name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_dummies = pd.concat(loan_data_dummies, axis = 1)\n",
    "# We concatenate the dummy variables and this turns them into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data_dummies)\n",
    "# Returns the type of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.concat([loan_data, loan_data_dummies], axis = 1)\n",
    "# Concatenates two dataframes.\n",
    "# Here we concatenate the dataframe with original data with the dataframe with dummy variables, along the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.columns.values\n",
    "# Displays all column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loan_data.isnull()\n",
    "# It returns 'False' if a value is not missing and 'True' if a value is missing, for each value in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "loan_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "# Sets the pandas dataframe options to display 100 columns/ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Total revolving high credit/ credit limit', so it makes sense that the missing values are equal to funded_amnt.\n",
    "loan_data['total_rev_hi_lim'].fillna(loan_data['funded_amnt'], inplace=True)\n",
    "# We fill the missing values with the values of another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['total_rev_hi_lim'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['annual_inc'].fillna(loan_data['annual_inc'].mean(), inplace=True)\n",
    "# We fill the missing values with the mean value of the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['mths_since_earliest_cr_line'].fillna(0, inplace=True)\n",
    "loan_data['acc_now_delinq'].fillna(0, inplace=True)\n",
    "loan_data['total_acc'].fillna(0, inplace=True)\n",
    "loan_data['pub_rec'].fillna(0, inplace=True)\n",
    "loan_data['open_acc'].fillna(0, inplace=True)\n",
    "loan_data['inq_last_6mths'].fillna(0, inplace=True)\n",
    "loan_data['delinq_2yrs'].fillna(0, inplace=True)\n",
    "loan_data['emp_length_int'].fillna(0, inplace=True)\n",
    "# We fill the missing values with zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent Variable. Good/ Bad (Default) Definition. Default and Non-default Accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['loan_status'].unique()\n",
    "# Displays unique values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data['loan_status'].value_counts()\n",
    "# Calculates the number of observations for each unique value of a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['loan_status'].value_counts() / loan_data['loan_status'].count()\n",
    "# We divide the number of observations for each unique value of a variable by the total number of observations.\n",
    "# Thus, we get the proportion of observations for each unique value of a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Good/ Bad Definition\n",
    "loan_data['good_bad'] = np.where(loan_data['loan_status'].isin(['Charged Off', 'Default',\n",
    "                                                       'Does not meet the credit policy. Status:Charged Off',\n",
    "                                                       'Late (31-120 days)']), 0, 1)\n",
    "# We create a new variable that has the value of '0' if a condition is met, and the value of '1' if it is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['good_bad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Imports the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split(loan_data.drop('good_bad', axis = 1), loan_data['good_bad'])\n",
    "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
    "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train, loan_data_inputs_test, loan_data_targets_train, loan_data_targets_test = train_test_split(loan_data.drop('good_bad', axis = 1), loan_data['good_bad'])\n",
    "# We split two dataframes with inputs and targets, each into a train and test dataframe, and store them in variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_train.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_test.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_test.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train, loan_data_inputs_test, loan_data_targets_train, loan_data_targets_test = train_test_split(loan_data.drop('good_bad', axis = 1), loan_data['good_bad'], test_size = 0.2, random_state = 42)\n",
    "# We split two dataframes with inputs and targets, each into a train and test dataframe, and store them in variables.\n",
    "# This time we set the size of the test dataset to be 20%.\n",
    "# Respectively, the size of the train dataset becomes 80%.\n",
    "# We also set a specific random state.\n",
    "# This would allow us to perform the exact same split multimple times.\n",
    "# This means, to assign the exact same observations to the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_train.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_test.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_test.shape\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation: An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "df_inputs_prepr = loan_data_inputs_train\n",
    "df_targets_prepr = loan_data_targets_train\n",
    "#####\n",
    "#df_inputs_prepr = loan_data_inputs_test\n",
    "#df_targets_prepr = loan_data_targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr['grade'].unique()\n",
    "# Displays unique values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df_inputs_prepr['grade'], df_targets_prepr], axis = 1)\n",
    "# Concatenates two dataframes along the columns.\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby(df1.columns.values[0], as_index = False)[df1.columns.values[1]].count()\n",
    "# Groups the data according to a criterion contained in one column.\n",
    "# Does not turn the names of the values of the criterion as indexes.\n",
    "# Aggregates the data in another column, using a selected function.\n",
    "# In this specific case, we group by the column with index 0 and we aggregate the values of the column with index 1.\n",
    "# More specifically, we count them.\n",
    "# In other words, we count the values in the column with index 1 for each value of the column with index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby(df1.columns.values[0], as_index = False)[df1.columns.values[1]].mean()\n",
    "# Groups the data according to a criterion contained in one column.\n",
    "# Does not turn the names of the values of the criterion as indexes.\n",
    "# Aggregates the data in another column, using a selected function.\n",
    "# Here we calculate the mean of the values in the column with index 1 for each value of the column with index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1.groupby(df1.columns.values[0], as_index = False)[df1.columns.values[1]].count(),\n",
    "                df1.groupby(df1.columns.values[0], as_index = False)[df1.columns.values[1]].mean()], axis = 1)\n",
    "# Concatenates two dataframes along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.iloc[:, [0, 1, 3]]\n",
    "# Selects only columns with specific indexes.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [df1.columns.values[0], 'n_obs', 'prop_good']\n",
    "# Changes the names of the columns of a dataframe.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['prop_n_obs'] = df1['n_obs'] / df1['n_obs'].sum()\n",
    "# We divide the values of one column by he values of another column and save the result in a new variable.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['n_good'] = df1['prop_good'] * df1['n_obs']\n",
    "# We multiply the values of one column by he values of another column and save the result in a new variable.\n",
    "df1['n_bad'] = (1 - df1['prop_good']) * df1['n_obs']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['prop_n_good'] = df1['n_good'] / df1['n_good'].sum()\n",
    "df1['prop_n_bad'] = df1['n_bad'] / df1['n_bad'].sum()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['WoE'] = np.log(df1['prop_n_good'] / df1['prop_n_bad'])\n",
    "# We take the natural logarithm of a variable and save the result in a nex variable.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(['WoE'])\n",
    "# Sorts a dataframe by the values of a given column.\n",
    "df1 = df1.reset_index(drop = True)\n",
    "# We reset the index of a dataframe and overwrite it.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1['diff_prop_good'] = df1['prop_good'].diff().abs()\n",
    "# We take the difference between two subsequent values of a column. Then, we take the absolute value of the result.\n",
    "df1['diff_WoE'] = df1['WoE'].diff().abs()\n",
    "# We take the difference between two subsequent values of a column. Then, we take the absolute value of the result.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['IV'] = (df1['prop_n_good'] - df1['prop_n_bad']) * df1['WoE']\n",
    "df1['IV'] = df1['IV'].sum()\n",
    "# We sum all values of a given column.\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Discrete Variables: Automating Calculaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoE function for discrete unordered variables\n",
    "def woe_discrete(df, discrete_variabe_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df = df.sort_values(['WoE'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df\n",
    "# Here we combine all of the operations above in a function.\n",
    "# The function takes 3 arguments: a dataframe, a string, and a dataframe. The function returns a dataframe as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'grade'\n",
    "df_temp = woe_discrete(df_inputs_prepr, 'grade', df_targets_prepr)\n",
    "# We execute the function we defined with the necessary arguments: a dataframe, a string, and a dataframe.\n",
    "# We store the result in a dataframe.\n",
    "df_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
